{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soynlp Tokenizer에 사용될 단어 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"data/2016-10-20.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30091"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터를 다수의 문서로 분리\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "\n",
    "corpus = DoublespaceLineCorpus(\"data/2016-10-20.txt\")\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.743 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "word_score_table = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/scores.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
    "joblib.dump(scores, 'data/scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=3929, neg=2321, common=107\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 403896 from 30091 sents. mem=0.817 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=4434442, mem=1.425 Gb\n",
      "[Noun Extractor] batch prediction was completed for 119705 words\n",
      "[Noun Extractor] checked compounds. discovered 70639 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 109312 -> 92205\n",
      "[Noun Extractor] postprocessing ignore_features : 92205 -> 91999\n",
      "[Noun Extractor] postprocessing ignore_NJ : 91999 -> 90643\n",
      "[Noun Extractor] 90643 nouns (70639 compounds) with min frequency=1\n",
      "[Noun Extractor] flushing was done. mem=1.557 Gb                    \n",
      "[Noun Extractor] 76.63 % eojeols are covered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/noun_scores.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.noun import LRNounExtractor_v2\n",
    "\n",
    "noun_ext = LRNounExtractor_v2(verbose=True)\n",
    "nouns = noun_ext.train_extract(corpus)\n",
    "noun_scores = {noun:score[0] for noun, score in nouns.items() if len(noun) > 1}\n",
    "joblib.dump(noun_scores, 'data/noun_scores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a1baeb1610b05443f415525bf52a486212d0ee94c2d320214bf0d7d56e225dd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vsc': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
